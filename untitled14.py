# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17lr6_77OORbRktfSvwAFGrPvta_YdVwr
"""

!pip install -U \
    gradio \
    numpy \
    scipy \
    pdfplumber \
    faster-whisper \
    google-genai

import gradio as gr
import numpy as np
import tempfile
import scipy.io.wavfile as wav
from faster_whisper import WhisperModel
import google.generativeai as genai
import pdfplumber

# =========================
# Gemini API（Colab Secret + Gemini 3 Pro Preview）
# =========================
from google.colab import userdata
import google.generativeai as genai

GOOGLE_API_KEY = userdata.get("GOOGLE_API_KEY")

if GOOGLE_API_KEY is None:
    raise RuntimeError("Colab Secret 中找不到 GEMINI_API_KEY")

genai.configure(api_key=GOOGLE_API_KEY)

try:
    llm = genai.GenerativeModel(
        model_name="gemini-3-pro-preview"
    )
except Exception as e:
    raise RuntimeError(
        "Gemini 模型初始化失敗，請確認 API Key 是否有 gemini-3-pro-preview 權限"
    ) from e

# =========================
# 2. Whisper 模型初始化
# =========================
whisper = WhisperModel(
    "small",
    device="cpu",
    compute_type="int8"
)

# =========================
# 3. 語音轉文字（防呆）
# =========================
def speech_to_text(audio):
    if audio is None:
        return ""

    try:
        sr, audio_data = audio
    except Exception:
        return ""

    if audio_data is None:
        return ""

    if audio_data.ndim > 1:
        audio_data = audio_data.mean(axis=1)

    try:
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        wav.write(tmp.name, sr, audio_data.astype(np.int16))

        segments, _ = whisper.transcribe(tmp.name, language="zh")
        text = "".join(seg.text for seg in segments).strip()
        return text
    except Exception:
        return ""

# =========================
# 3.5 解析履歷 PDF
# =========================
def extract_text_from_pdf(pdf_file):
    if pdf_file is None:
        return ""

    text = ""
    with pdfplumber.open(pdf_file.name) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"

    return text.strip()

# =========================
# 4. 產生第一題面試問題（防格式錯誤）
# =========================
def generate_question(resume, jd):
    if resume.strip() == "" or jd.strip() == "":
        return "請先輸入履歷與職缺 JD"

    prompt = f"""
以下是使用者的履歷：
{resume}

以下是職缺 JD：
{jd}

請根據該職位需要的能力，產生 1 高品質的面試問題。

嚴格要求：
- 只能輸出一行
- 不要編號
- 不要加任何說明
- 不要加「面試問題：」字樣

問題需：
- 結合該使用者履歷的弱點或缺乏證據之處
- 可為行為題或情境題
- 可同時觀察 Hard Skills + Soft Skills
"""

    try:
        resp = llm.generate_content(prompt)
        if resp is None or resp.text is None:
            return "面試問題產生失敗，請重試"

        return resp.text.strip().split("\n")[0]
    except Exception:
        return "面試問題產生失敗，請確認 API 狀態"

# =========================
# 5. STAR 評分（完整依文件）
# =========================
def evaluate_star(answer):
    if answer.strip() == "":
        return "未偵測到有效回答內容，請重新作答"

    prompt = f"""
以下是候選人的面試回答：
{answer}

請依照 STAR（Situation, Task, Action, Result）評分，並輸出：

STAR 評分（0–10 分）
- Situation（情境描述）：
- Task（任務清晰度）：
- Action（行動細節）：
- Result（成果具體度）：

總分（加總後 / 40 分）

問題診斷
請說明使用者回答的問題，例如：
- 情境太長
- 行動太模糊
- 缺乏數據
- 沒有提到困難點與反思

建議改寫
請協助使用者把回答改成更優秀的 STAR 版本（不超過 150 字）。
"""

    try:
        resp = llm.generate_content(prompt)
        if resp is None or resp.text is None:
            return "STAR 評分失敗，請重試"

        return resp.text.strip()
    except Exception:
        return "STAR 評分失敗，請確認 API 狀態"

# =========================
# 6. 產生下一題（難度提升）
# =========================
def generate_next_question(resume, jd, answer):
    prompt = f"""
以下是使用者的履歷：
{resume}

以下是職缺 JD：
{jd}

以下是使用者剛才的面試回答：
{answer}

請根據使用者之前的回答弱點，
產生 1 題難度略高於上一題的面試問題。

嚴格要求：
- 只能輸出一行
- 不要編號
- 不要加任何說明
"""

    try:
        resp = llm.generate_content(prompt)
        if resp is None or resp.text is None:
            return "下一題產生失敗，請重試"

        return resp.text.strip().split("\n")[0]
    except Exception:
        return "下一題產生失敗，請確認 API 狀態"

# =========================
# 7. 面試流程整合
# =========================
def interview_pipeline(resume, jd, audio):
    user_answer = speech_to_text(audio)

    if user_answer == "":
        return "未偵測到語音內容", "", ""

    evaluation = evaluate_star(user_answer)
    next_q = generate_next_question(resume, jd, user_answer)

    return user_answer, evaluation, next_q

# =========================
# 8. Gradio UI
# =========================
with gr.Blocks() as demo:
    gr.Markdown("## AI 模擬面試（支援履歷 PDF 上傳）")

    # === 履歷 PDF 上傳 ===
    resume_pdf = gr.File(
        label="請拖入履歷 PDF",
        file_types=[".pdf"]
    )

    resume_box = gr.Textbox(
        label="解析後的履歷內容（自動產生）",
        lines=10
    )

    parse_btn = gr.Button("解析履歷 PDF")

    parse_btn.click(
        fn=extract_text_from_pdf,
        inputs=resume_pdf,
        outputs=resume_box
    )

    # === 職缺 JD ===
    jd_box = gr.Textbox(label="職缺 JD", lines=8)

    # === 面試題目 ===
    question_box = gr.Textbox(label="面試問題", lines=3)
    gen_btn = gr.Button("產生面試問題")

    gen_btn.click(
        fn=generate_question,
        inputs=[resume_box, jd_box],
        outputs=question_box
    )

    # === 語音回答 ===
    audio = gr.Audio(
        sources=["microphone"],
        type="numpy",
        label="語音回答"
    )

    answer_text = gr.Textbox(label="語音轉文字結果", lines=3)
    feedback = gr.Textbox(label="STAR 評分與建議", lines=10)
    next_question = gr.Textbox(label="下一題面試問題", lines=3)

    submit = gr.Button("送出回答")

    submit.click(
        fn=interview_pipeline,
        inputs=[resume_box, jd_box, audio],
        outputs=[answer_text, feedback, next_question]
    )

demo.launch(debug=True)

